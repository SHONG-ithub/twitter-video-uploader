import cv2
import numpy as np
import librosa
import subprocess
import tempfile
import os
from tqdm import tqdm

# ======================
# è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# ======================
INPUT_FILE = "input.mp4"
OUTPUT_FILE = "output_trim.mp4"

SAFE_MODE = False  # â† True=éã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰ / False=ã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰
SAFE_MODE = True  # â† True=éã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰ / False=ã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰

FRAME_INTERVAL = 0.5   # ç§’é–“éš”ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
SKIN_THRESHOLD = 0.25  # è‚Œè‰²ç‡ãŒã“ã®å€¤ã‚’è¶…ãˆãŸã‚‰ã‚¨ãƒ­å¯„ã‚Š
RMS_THRESHOLD_RATIO = 2.0  # å¹³å‡éŸ³é‡ã®ä½•å€ä»¥ä¸Šã§ã€Œå–˜ãå£°ã€
TRIM_LENGTH = 20       # å‡ºåŠ›ç§’æ•°ï¼ˆæœ€å¤§å€¤ï¼‰

# é»’èƒŒæ™¯ã‚¿ã‚¤ãƒˆãƒ«é™¤å»ç”¨
BLACK_THRESHOLD = 20       # å¹³å‡æ˜åº¦ãŒã“ã®å€¤ä»¥ä¸‹ã‚’ã€Œé»’ã€ã¨ã¿ãªã™
BLACK_CONTINUE_SEC = 2.0   # é»’ãŒä½•ç§’ä»¥ä¸Šç¶šã„ãŸã‚‰ã‚¿ã‚¤ãƒˆãƒ«åˆ¤å®š

# ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ¤œå‡ºç”¨
SCENE_DIFF_THRESHOLD = 0.35   # ã©ã®ç¨‹åº¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ å·®ã‚’ã‚·ãƒ¼ãƒ³å¤‰åŒ–ã¨ã¿ãªã™ã‹
SCENE_ADJUST_MARGIN = 2.0     # çµ‚ç«¯è£œæ­£ç¯„å›²ï¼ˆç§’ï¼‰

# ======================
# è‚Œè‰²ï¼‹æ˜åº¦è§£æ
# ======================
def analyze_skin_ratio_and_brightness(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    interval = int(fps * FRAME_INTERVAL)

    ratios, brightness = [], []
    for i in tqdm(range(0, frame_count, interval), desc="è§£æä¸­ï¼ˆè‚Œè‰²ç‡ãƒ»æ˜åº¦ï¼‰"):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if not ret:
            break
        img_ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
        mask = cv2.inRange(img_ycrcb, (0, 133, 77), (255, 173, 127))
        ratio = np.sum(mask > 0) / mask.size
        ratios.append(ratio)

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        brightness.append(np.mean(gray))
    cap.release()
    return np.array(ratios), np.array(brightness), duration

# ======================
# éŸ³å£°è§£æ
# ======================
def analyze_audio(video_path):
    tmp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    cmd = ["ffmpeg", "-y", "-i", video_path, "-vn", "-ac", "1", "-ar", "44100", "-f", "wav", tmp_wav]
    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    y, sr = librosa.load(tmp_wav, sr=None)
    os.remove(tmp_wav)
    rms = librosa.feature.rms(y=y)[0]
    avg = np.mean(rms)
    loudness = rms > avg * RMS_THRESHOLD_RATIO
    loud_ratio = np.sum(loudness) / len(loudness)
    return loud_ratio, rms, sr

# ======================
# é»’èƒŒæ™¯ã‚¿ã‚¤ãƒˆãƒ«æ¤œå‡º
# ======================
def detect_black_title(brightness, duration):
    step = FRAME_INTERVAL
    dark = brightness < BLACK_THRESHOLD
    dark_len = 0
    black_end_time = 0.0
    for i, is_dark in enumerate(dark):
        if is_dark:
            dark_len += step
        else:
            if dark_len >= BLACK_CONTINUE_SEC:
                black_end_time = i * step
            break
    if black_end_time > 0:
        print(f"ğŸ•¶ï¸ é»’èƒŒæ™¯ã‚¿ã‚¤ãƒˆãƒ«æ¤œå‡º: {black_end_time:.1f} ç§’ã¾ã§ã‚¹ã‚­ãƒƒãƒ—")
    return black_end_time

# ======================
# ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ¤œå‡º
# ======================
def detect_scene_changes(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    interval = int(fps * 0.5)
    prev_hist = None
    changes = []

    for i in range(0, frame_count, interval):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if not ret:
            break
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        hist = cv2.calcHist([hsv], [0, 1], None, [50, 60], [0, 180, 0, 256])
        cv2.normalize(hist, hist)
        if prev_hist is not None:
            diff = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_BHATTACHARYYA)
            if diff > SCENE_DIFF_THRESHOLD:
                changes.append(i / fps)
        prev_hist = hist
    cap.release()
    print(f"ğŸï¸ ã‚·ãƒ¼ãƒ³å¤‰åŒ– {len(changes)} ç®‡æ‰€æ¤œå‡º")
    return changes

# ======================
# åŒºé–“æ¤œå‡ºï¼ˆSAFE_MODEã«å¿œã˜ã¦ï¼‰
# ======================
def find_target_section(skin_ratios, brightness, duration, skip_until, safe_mode):
    step = FRAME_INTERVAL
    if safe_mode:
        condition = (skin_ratios < SKIN_THRESHOLD) & (brightness > BLACK_THRESHOLD)
    else:
        condition = (skin_ratios >= SKIN_THRESHOLD) & (brightness > BLACK_THRESHOLD)

    valid_indices = [i for i, ok in enumerate(condition) if ok and i * step > skip_until]
    if len(valid_indices) == 0:
        print("âŒ æ¡ä»¶ã«åˆã†åŒºé–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None, None

    if safe_mode:
        start = valid_indices[0] * step
        end = min(start + TRIM_LENGTH, duration)
        print(f"âœ… éã‚¨ãƒ­åŒºé–“: {start:.1f}ã€œ{end:.1f} ç§’")
    else:
        diffs = np.diff(valid_indices)
        segments = []
        seg_start = valid_indices[0]
        for i, d in enumerate(diffs):
            if d > 1:
                segments.append((seg_start, valid_indices[i]))
                seg_start = valid_indices[i + 1]
        segments.append((seg_start, valid_indices[-1]))
        seg = max(segments, key=lambda x: x[1] - x[0])
        start = seg[0] * step
        end = min(seg[1] * step + TRIM_LENGTH, duration)
        print(f"ğŸ”¥ ã‚¨ãƒ­åŒºé–“: {start:.1f}ã€œ{end:.1f} ç§’")
    return start, end

# ======================
# çµ‚ç«¯èª¿æ•´ï¼ˆã‚·ãƒ¼ãƒ³å¢ƒç•Œã§åˆ‡ã‚‹ï¼‰
# ======================
def adjust_to_scene_end(start, end, scene_changes):
    for t in scene_changes:
        if start < t < end:
            # çµ‚äº†æ™‚é–“ã®å°‘ã—å‰ã«ã‚·ãƒ¼ãƒ³åˆ‡ã‚Šæ›¿ãˆãŒã‚ã‚Œã°ãã“ã¾ã§ã«ã™ã‚‹
            if end - t < SCENE_ADJUST_MARGIN:
                print(f"âœ‚ï¸ ã‚·ãƒ¼ãƒ³å¢ƒç•Œã«åˆã‚ã›ã¦çµ‚äº†æ™‚åˆ»ã‚’ {t:.1f} ç§’ã«èª¿æ•´")
                return start, t
    return start, end

# ======================
# ffmpegãƒˆãƒªãƒŸãƒ³ã‚°
# ======================
def trim_video(video_path, start, end, out_path):
    cmd = ["ffmpeg", "-y", "-ss", str(start), "-to", str(end), "-i", video_path, "-c", "copy", out_path]
    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    print(f"ğŸ¬ å‡ºåŠ›å®Œäº†: {out_path}")

def process_and_trim_video(video_url: str, work_dir: str = "/tmp") -> dict:
    """
    FANZAã‚µãƒ³ãƒ—ãƒ«å‹•ç”»URLã‚’å—ã‘å–ã‚Šã€
    - ffmpeg ã§ãƒ­ãƒ¼ã‚«ãƒ«ã«DL
    - è§£æï¼†SAFE_MODEã§éã‚¨ãƒ­åŒºé–“ã‚’æ±ºå®š
    - ffmpegã§ãƒˆãƒªãƒŸãƒ³ã‚°
    ã‚’è¡Œã„ã€çµæœãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ dict ã§è¿”ã™ã€‚
    """
    import uuid

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ±ºã‚ã‚‹
    base = f"fanza_{uuid.uuid4().hex}.mp4"
    input_path = os.path.join(work_dir, base)
    output_path = os.path.join(work_dir, base.replace(".mp4", "_trim.mp4"))

    # å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä»Šã® __main__ ã¨åŒã˜ã‚„ã‚Šæ–¹ï¼‰
    print(f"â–¶ FANZAå‹•ç”»DLé–‹å§‹: {video_url}")
    cmd_dl = ["ffmpeg", "-y", "-i", video_url, "-c", "copy", input_path]
    subprocess.run(cmd_dl, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    if not os.path.exists(input_path):
        raise RuntimeError("å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

    mode = "éã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰" if SAFE_MODE else "ã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰"
    print(f"â–¶ è§£æé–‹å§‹: {input_path} ({mode})")

    # === è§£æãƒ‘ãƒ¼ãƒˆï¼ˆæ—¢å­˜å‡¦ç†ã‚’ãã®ã¾ã¾åˆ©ç”¨ï¼‰ ===
    skin_ratios, brightness, duration = analyze_skin_ratio_and_brightness(input_path)
    loud_ratio, rms, sr = analyze_audio(input_path)
    print(f"éŸ³é‡è§£æ: loud_ratio={loud_ratio:.2f}")

    skip_until = detect_black_title(brightness, duration)
    scene_changes = detect_scene_changes(input_path)

    start, end = find_target_section(skin_ratios, brightness, duration, skip_until, SAFE_MODE)
    if start is None:
        print("âŒ ãƒˆãƒªãƒŸãƒ³ã‚°å¯¾è±¡åŒºé–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return {
            "status": "fail",
            "reason": "no_safe_section",
            "input_path": input_path,
        }

    start, end = adjust_to_scene_end(start, end, scene_changes)
    trim_video(input_path, start, end, output_path)

    print(f"âœ… å‡ºåŠ›å®Œäº†: {output_path}")
    return {
        "status": "success",
        "input_path": input_path,
        "output_path": output_path,
        "start": start,
        "end": end,
        "duration": duration,
        "safe_mode": SAFE_MODE,
    }

# ======================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ======================
if __name__ == "__main__":
    import sys
    import requests

    if len(sys.argv) >= 3:
        video_url = sys.argv[1]
        local_path = sys.argv[2]
        print(f"â–¶ FANZAå‹•ç”»DLé–‹å§‹: {video_url}")
        subprocess.run(["ffmpeg", "-y", "-i", video_url, "-c", "copy", local_path])
        INPUT_FILE = local_path
        OUTPUT_FILE = local_path.replace(".mp4", "_trim.mp4")

    mode = "éã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰" if SAFE_MODE else "ã‚¨ãƒ­ãƒ¢ãƒ¼ãƒ‰"
    print(f"â–¶ è§£æé–‹å§‹: {INPUT_FILE} ({mode})")

    skin_ratios, brightness, duration = analyze_skin_ratio_and_brightness(INPUT_FILE)
    loud_ratio, rms, sr = analyze_audio(INPUT_FILE)
    print(f"éŸ³é‡è§£æ: loud_ratio={loud_ratio:.2f}")

    skip_until = detect_black_title(brightness, duration)
    scene_changes = detect_scene_changes(INPUT_FILE)

    start, end = find_target_section(skin_ratios, brightness, duration, skip_until, SAFE_MODE)
    if start is not None:
        start, end = adjust_to_scene_end(start, end, scene_changes)
        trim_video(INPUT_FILE, start, end, OUTPUT_FILE)
        print(f"âœ… å‡ºåŠ›å®Œäº†: {OUTPUT_FILE}")
        with open("status.json", "w", encoding="utf-8") as f:
            f.write('{"status":"success","output":"'+OUTPUT_FILE+'"}')
    else:
        print("âŒ ãƒˆãƒªãƒŸãƒ³ã‚°å¤±æ•—")
        with open("status.json", "w", encoding="utf-8") as f:
            f.write('{"status":"fail"}')
